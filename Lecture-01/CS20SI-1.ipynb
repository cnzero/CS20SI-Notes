{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to TensorFlow\n",
    "\n",
    "- Welcome\n",
    "- Overview of TensorFlow\n",
    "- Graphs and Sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why TensorFlow\n",
    "1. Python API;\n",
    "2. Portability - 可迁移性。 能够适用于单个或多个CPU、GPU、服务器，或者移动设备；\n",
    "3. Flexibility - 弹性。 从树莓派、安卓、Windows、iOS、Linux到服务器集群；\n",
    "4. Visualization - 可视化。 其中重要的TensorBoard功能。\n",
    "5. Checkpoints - 断点。 可用于管理诸多实验。\n",
    "6. Auto-differentiation - 自动微分。不再需要手动求微分。\n",
    "7. Large community。 丰富的社区讨论等。\n",
    "8. 大量已经使用TensorFlow搭建的项目。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从《TensorFlow for Machine Intelligence》中引用：\n",
    "> While the mathematical concepts behind deep learning have been around for decades, programming libraries dedicated to creating and training these deep models have only been available in recent years.\n",
    "\n",
    "尽管_深度学习_ 背后的数学原理已经出现了很多年，但是针对搭建与训练深层次网络的代码库也仅仅是这几年才有的。\n",
    "\n",
    "> Unfortunately, most of these libraries have a large trade off between flexibility and production-worthiness. \n",
    "\n",
    "> Flexible libraries are invaluable for researching novel model architectures, but are often either too slow or incapable of being used in production.\n",
    "\n",
    "> On the other hand, fast, efficient, libraries which can be hosted on distributed hardware are avaiable, \n",
    "\n",
    "> but they often specialize in specific types of neural networks and aren't suited to researching new and better models. \n",
    "\n",
    "> This leaves decision makers with a dilemma: should we attempt to do research with inflexible libraries so that we don't have to reimplement code, \n",
    "\n",
    "> Or should we use one library for research and a completely different types of neural networks for production?\n",
    "\n",
    "> If we choose the latter, we have to maintain code that may have completely different APIs.\n",
    "\n",
    "> Do we even have the resources for this?\n",
    "\n",
    "> TensorFlow aims to solve this dilemma.\n",
    "\n",
    "TensorFlow 旨在解决几方面之间的矛盾：\n",
    "- 研究的灵活性\n",
    "- 产品的易用性\n",
    "- 分布式硬件支持\n",
    "- 探索新的神经网络模型\n",
    "- 等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "知乎上 [贾扬清](https://www.zhihu.com/people/jiayangqing)针对[TensorFlow有哪些令人难以接受的地方？](https://www.zhihu.com/question/63342728/answer/208898814)这一问题也表达了类似的观点。 \n",
    "> 上来给TF说句公道话：TF是目前唯一一个在核心设计层面上支持dynamic control flow的框架，也是极少几个经历大规模多应用部署考验的的框架之一。\n",
    "\n",
    "> 很多人感觉其他框架好的理由，是它们绕开了实际应用中的限制条件。比如说imperative mode做control flow，很多框架其实并不是自己做control flow，而是利用python来做，框架自己只记录一个static graph。\n",
    "\n",
    "> 这样的缺点是你没法部署到真正核心的产品里面，一旦要部署，就必须回到static graph去 - 很多产品，比如大规模推荐系统和移动端，是不可能用python的，overhead太大。\n",
    "\n",
    ">所以要写好的解决方案，哪个框架都要很小心才行。TF的确难，但是它给你提供了真正可以产品化的可能性。\n",
    "\n",
    "> 对了，当年谁说我是专业TF黑来着？\n",
    "\n",
    "> 要相信Jeff Dean大神的眼光还是很不错的，很多问题只看见一棵树的时候简单，看见森林的时候，解决方法就不一样了。\n",
    "\n",
    "作者：贾扬清\n",
    "链接：https://www.zhihu.com/question/63342728/answer/208898814\n",
    "来源：知乎\n",
    "著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals - 目标\n",
    "1. 理解TensorFlow的计算图方法；\n",
    "2. 探索TensorFlow内置函数；\n",
    "3. 学习构建并结构化深度学习的项目。\n",
    "\n",
    "> Off-the-shelf model are not the main purpose of TensorFlow.\n",
    "\n",
    "> TensorFlow provides an extensive suite of functions and classes that allow users to define models from scratch.\n",
    "\n",
    "> And this is what we are going to learn. \n",
    "\n",
    "我们不是要使用TensorFlow中现成的模型，而是要学会从零搭建自己的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Books\n",
    "- TensorFlow for Machine Intelligence\n",
    "- Hands-on Machine Learning with Scikit-learn and TensorFlow\n",
    "- Fundamentals of Deep Learning\n",
    "\n",
    "相对而言，TensorFlow发展迅速，书很快就会过时，所以要通过 [官网](https://www.tensorflow.org/)跟踪最新。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two phases with TensorFlow\n",
    "- Phase 1: assemble a graph 构建一个计算图\n",
    "- Phase 2: use a session to execute operations in the graph. 利用一个session执行该计算图（自动进行微分更新参数）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a tensor?\n",
    "- 0维：标量；\n",
    "- 1维：向量；\n",
    "- 2维：矩阵；\n",
    "- 等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Session?\n",
    "A __Session__ object encapsulates the environment in which Operations objects are executed, and Tensor objects are evaluated. \n",
    "\n",
    "__Session__ 封装一个计算环境，其中完成了 _操作_ 的执行，并计算相应的 _张量_ 。\n",
    "\n",
    "The Session will also allocate memory to store the current value of the variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why graphs\n",
    "1. 节省计算量。 仅运行只跟所求的变量相关的部分计算图。\n",
    "2. 将计算分割成小块，每一部分便于进行自动微分。\n",
    "3. 方便进行分布式计算，跨多个CPU、GPU或设备等。\n",
    "4. 许多常用的机器学习模型已经训练并通过计算图进行可视化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小结\n",
    "这一章在自我摸索的情况下，竟然能够正确输出TensorBoard的展示，也算是一个小意外了。 \n",
    "\n",
    "还是从整体性介绍TensorFlow，有谁在用，为什么要用，该如何使用。\n",
    "\n",
    "__该如何使用__ 最为重要， 我们希望能够充分利用TensorFlow已经定义好的模块，如各种函数和类，但是最核心的模型部分，还是得从头搭建。\n",
    "\n",
    "并且特别强调 Computational Graph 计算图这个核心问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "x = tf.constant(3, name='x')\n",
    "y = tf.constant(5, name='y')\n",
    "add_op = tf.add(x, y)\n",
    "mul_op = tf.multiply(x, y)\n",
    "useless = tf.multiply(x, add_op)\n",
    "pow_op = tf.pow(add_op, mul_op)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(useless))\n",
    "    summary_writer = tf.summary.FileWriter('tmp/testtb', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TensorBoard Visualization](lecture1.JPG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
