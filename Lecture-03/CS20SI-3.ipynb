{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Models in TensorFlow\n",
    "- Review\n",
    "- Linear regression in TensorFlow\n",
    "- Optimizers\n",
    "- Logistic regression on MNIST\n",
    "- Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "### Phase 1: Assemble our graph\n",
    "1. Read in data\n",
    "2. Create placeholders for inputs and labels\n",
    "3. Create weight and bias\n",
    "4. Build model to predict Y\n",
    "5. Specify loss function\n",
    "6. Create optimizer\n",
    "\n",
    "### Phase 2: Train our model\n",
    "1. initialize variables\n",
    "2. run optimizer operation with data fed into placeholders for inputs and labels. \n",
    "\n",
    "### See your model in TensorBoard\n",
    "1. `writer = tf.summary.FileWriter('folder', sess.graph)`\n",
    "2. `tensorboard --logdir=folder`\n",
    "\n",
    "### Plot the results with matplotlib\n",
    "1. uncomment the plotting code at the end of your program\n",
    "2. run it again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784)\n",
      "(55000, 10)\n",
      "(5000, 784)\n",
      "(5000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "MNIST = input_data.read_data_sets('MNIST_data/', one_hot=True)\n",
    "print(MNIST.train.images.shape)\n",
    "print(MNIST.train.labels.shape)\n",
    "print(MNIST.validation.images.shape)\n",
    "print(MNIST.validation.labels.shape)\n",
    "print(MNIST.test.images.shape)\n",
    "print(MNIST.test.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def huber_loss(labels, predictions, delta=1.0):\n",
    "    residual = tf.abs(predictions - labels)\n",
    "    condition = tf.less(residual, delta)\n",
    "    small_res = 0.5 * tf.square(residual)\n",
    "    large_res = delta * residual - 0.5*tf.square(delta)\n",
    "    return tf.where(condition, small_res, large_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.53255\n",
      "0.278037\n",
      "0.512715\n",
      "0.219328\n",
      "0.281077\n",
      "0.336848\n",
      "0.319868\n",
      "0.204742\n",
      "0.200012\n",
      "0.137681\n",
      "0.312426\n",
      "0.345597\n",
      "0.165318\n",
      "0.0764051\n",
      "0.312421\n",
      "0.167989\n",
      "0.195499\n",
      "0.302\n",
      "0.205548\n",
      "0.226895\n",
      "Training set accuracy:\n",
      "0.931964\n",
      "Testing set accuracy:\n",
      "0.9262\n"
     ]
    }
   ],
   "source": [
    "batch_size = None\n",
    "with tf.name_scope('data'):\n",
    "    X = tf.placeholder(tf.float32, [batch_size, 784], name='image')\n",
    "    Y = tf.placeholder(tf.float32, [batch_size, 10], name='label')\n",
    "\n",
    "W = tf.Variable(tf.zeros([784, 10]), name='W')\n",
    "b = tf.Variable(tf.zeros([10]), name='b')\n",
    "\n",
    "# logits = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "logits = tf.matmul(X, W) + b\n",
    "\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y)\n",
    "loss = tf.reduce_mean(entropy)\n",
    "# loss = tf.reduce_mean(huber_loss(labels=Y, predictions=logits))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate=.5).minimize(loss)\n",
    "# train_step = tf.train.AdamOptimizer(learning_rate=0.05).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter('tmp/', sess.graph)\n",
    "    for i in range(10000):\n",
    "        batch_x, batch_y = MNIST.train.next_batch(100)\n",
    "        sess.run(train_step, feed_dict = {X:batch_x, Y:batch_y})\n",
    "        if i%500 == 0:\n",
    "            print(sess.run(loss, feed_dict = {X:batch_x, Y:batch_y}) )\n",
    "#             print(sess.run(accuracy, feed_dict={X: batch_x, Y:batch_y}))\n",
    "\n",
    "\n",
    "    print('Training set accuracy:')\n",
    "    print(sess.run(accuracy, feed_dict={X:MNIST.train.images, Y:MNIST.train.labels}))\n",
    "    print('Testing set accuracy:')\n",
    "    print(sess.run(accuracy, feed_dict={X:MNIST.test.images, Y:MNIST.test.labels}))\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Lecture-03-MNIST-softmax.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [MNIST for Beginners](https://www.tensorflow.org/get_started/mnist/beginners)\n",
    "TensorFlow 的官网教程中也介绍了利用Softmax，有比较详细的介绍。\n",
    "\n",
    "基于与上述例程一样，同时相对而言，也比较简单，不再一一说明。\n",
    "\n",
    "但是，[Deep MNIST for Experts](https://www.tensorflow.org/get_started/mnist/pros) 想比较透彻地扣一扣。\n",
    "\n",
    "__Deep MNIST for Experts__ 参考另外一篇 [Notebook 文档](Deep MNIST for Experts.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "本文所介绍的一系列步骤，就是利用TensorFlow解决任何机器学习问题的指南。\n",
    "\n",
    "- Steps\n",
    "- Phase 1: Assemble our graph\n",
    "    1. Read in data\n",
    "    2. Create placeholders for inputs and labels\n",
    "    3. Create weight and bias\n",
    "    4. Build model to predict Y\n",
    "    5. Specify loss function\n",
    "    6. Create optimizer\n",
    "\n",
    "- Phase 2: Train our model\n",
    "    1. initialize variables\n",
    "    2. run optimizer operation with data fed into placeholders for inputs and labels. \n",
    "\n",
    "- See your model in TensorBoard\n",
    "    1. `writer = tf.summary.FileWriter('folder', sess.graph)`\n",
    "    2. `tensorboard --logdir=folder`\n",
    "\n",
    "- Plot the results with matplotlib\n",
    "    1. uncomment the plotting code at the end of your program\n",
    "    2. run it again. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
