{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Models in TensorFlow\n",
    "- Review\n",
    "- Linear regression in TensorFlow\n",
    "- Optimizers\n",
    "- Logistic regression on MNIST\n",
    "- Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "### Phase 1: Assemble our graph\n",
    "1. Read in data\n",
    "2. Create placeholders for inputs and labels\n",
    "3. Create weight and bias\n",
    "4. Build model to predict Y\n",
    "5. Specify loss function\n",
    "6. Create optimizer\n",
    "\n",
    "### Phase 2: Train our model\n",
    "1. initialize variables\n",
    "2. run optimizer operation with data fed into placeholders for inputs and labels. \n",
    "\n",
    "### See your model in TensorBoard\n",
    "1. `writer = tf.summary.FileWriter('folder', sess.graph)`\n",
    "2. `tensorboard --logdir=folder`\n",
    "\n",
    "### Plot the results with matplotlib\n",
    "1. uncomment the plotting code at the end of your program\n",
    "2. run it again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def huber_loss(labels, predictions, delta=1.0):\n",
    "    residual = tf.abs(predictions - labels)\n",
    "    condition = tf.less(residual, delta)\n",
    "    small_res = 0.5 * tf.square(residual)\n",
    "    large_res = delta * residual - 0.5*tf.square(delta)\n",
    "    return tf.select(condition, small_res, large_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784)\n",
      "(55000, 10)\n",
      "(5000, 784)\n",
      "(5000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "MNIST = input_data.read_data_sets('MNIST_data/', one_hot=True)\n",
    "print(MNIST.train.images.shape)\n",
    "print(MNIST.train.labels.shape)\n",
    "print(MNIST.validation.images.shape)\n",
    "print(MNIST.validation.labels.shape)\n",
    "print(MNIST.test.images.shape)\n",
    "print(MNIST.test.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.29059\n",
      "0.44\n",
      "Training set accuracy:\n",
      "0.84011\n",
      "Testing set accuracy:\n",
      "0.8503\n"
     ]
    }
   ],
   "source": [
    "batch_size = None\n",
    "with tf.name_scope('data'):\n",
    "    X = tf.placeholder(tf.float32, [batch_size, 784], name='image')\n",
    "    Y = tf.placeholder(tf.float32, [batch_size, 10], name='label')\n",
    "\n",
    "W = tf.Variable(tf.zeros([784, 10]), name='W')\n",
    "b = tf.Variable(tf.zeros([10]), name='b')\n",
    "\n",
    "logits = tf.matmul(X, W) + b\n",
    "\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y)\n",
    "loss = tf.reduce_mean(entropy)\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate=.01).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter('tmp/CS20SI3/', sess.graph)\n",
    "    for i in range(500):\n",
    "        batch_x, batch_y = MNIST.train.next_batch(500)\n",
    "        sess.run(train_step, feed_dict = {X:batch_x, Y:batch_y})\n",
    "        if i%500 == 0:\n",
    "            print(sess.run(loss, feed_dict = {X:batch_x, Y:batch_y}) )\n",
    "            print(sess.run(accuracy, feed_dict={X: batch_x, Y:batch_y}))\n",
    "\n",
    "\n",
    "    print('Training set accuracy:')\n",
    "    print(sess.run(accuracy, feed_dict={X:MNIST.train.images, Y:MNIST.train.labels}))\n",
    "    print('Testing set accuracy:')\n",
    "    print(sess.run(accuracy, feed_dict={X:MNIST.test.images, Y:MNIST.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Lecture-03-MNIST-softmax.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
